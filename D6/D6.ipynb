{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f140fe3e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"D6.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4398a36e",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a778960840d4bde7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# COGS 118A: Discussion Lab 6\n",
    "\n",
    "### Instructions\n",
    "\n",
    "You are responsible for making sure you pass all public tests on Gradescope. \n",
    "\n",
    "\n",
    "Note: D6 does not contain any quiz questions. When you submit this lab, you **must** submit your jupyter notebook only. \n",
    "\n",
    "**If you do not do this, you will not receive credit for the assignment.**\n",
    "\n",
    "In this discussion lab, you will learn more about optimization methods and multi-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecd3d028",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9a8cffb9a3c840d9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix, f1_score, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e49e1ce",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9137e196e3f21902",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Optimization\n",
    "\n",
    "You should think about machine learning algorithms and machine learning optimizers as two separate concepts.\n",
    "\n",
    "A machine learning algorithm, such as lasso logistic regression, defines a hypothesis space over possible models (here a hypothesis is a particular parameterization). A machine learning optimizer is a program which tries to find the best model in the hypothesis space.\n",
    "\n",
    "Here you will try your hand at selecting optimizers. For different problems, different optimizers might yield different results, might converge to a solution faster, or might not converge at all.\n",
    "\n",
    "## Background:\n",
    "\n",
    "Imagine you are a researcher investigating how genetic, environmental, and experimental conditions affect protein expressions. Specifically, you want to see which protein expressions are predictive of genomic factors (downs syndrome vs non-downs syndrome), environmental factors (shock conditioning vs no shock conditioning), and drug conditions (saline injection vs drug injection).\n",
    "\n",
    "You have collected a dataset to answer this question and your goal now is to fit a model which can identify subsets of proteins that are discriminant between a classes (unique combinations of genomic, environmental factors, and drug condition categories).\n",
    "\n",
    "[UCI repository](https://archive.ics.uci.edu/ml/datasets/Mice+Protein+Expression)\n",
    "\n",
    "## Problem:\n",
    "\n",
    "Your problem is to find the best lasso logistic regression model (this is logistic regression with an l1 regularization penalty) for this dataset. Here best is defined using f1-micro. To do this, you will use grid search over optimizers. This is a good opportunity to read through the [sklearn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). (Hint: not all solvers are compatible with `l1` regularization)\n",
    "\n",
    "NOTE: you might run into a convergence error meaning that the optimizer never reached a stable solution. This is bad but don't panic. Maybe not all optimizers are well suited to the problem :) and _maybe_ one is.\n",
    "\n",
    "Your plot should look something like the following:\n",
    "\n",
    "![output](./index.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a32aac5d",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bde24f5692b14749",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('https://archive.ics.uci.edu/ml/machine-learning-databases/00342/Data_Cortex_Nuclear.xls')\n",
    "y = df.loc[:, \"class\"]\n",
    "X = df.loc[:, ~df.columns.isin([\"class\", \"Genotype\", \"Behavior\", \"Treatment\", \"MouseID\"])]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6758214",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2c566a7964dfd6e3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# for debugging purposes!\n",
    "# don't use this for the final submission, but this can help you iterate faster\n",
    "subsample_df = df.groupby(by=[\"class\", \"MouseID\"]).apply(lambda gdf: gdf.sample(frac=0.1))\n",
    "sample_y = df.loc[:, \"class\"]\n",
    "sample_X = df.loc[:, ~df.columns.isin([\"class\", \"Genotype\", \"Behavior\", \"Treatment\", \"MouseID\"])]\n",
    "#sample_X = sample_X.iloc[:, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b369bf9",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0e95e0dce6b27752",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_results(gridsearchcv):\n",
    "    params = gridsearchcv.cv_results_[\"params\"]\n",
    "    ys = gridsearchcv.cv_results_[\"mean_test_score\"]\n",
    "    xs = ['|'.join(str(v) for v in param.values()) for param in params]\n",
    "    yerr = gridsearchcv.cv_results_[\"std_test_score\"]\n",
    "    plt.errorbar(xs, ys, yerr / np.sqrt(gridsearchcv.cv), fmt='.k')\n",
    "    plt.ylabel(\"f1\")\n",
    "    plt.xlabel(\"params\")\n",
    "    \n",
    "def check_for_convergence(gridsearchcv):\n",
    "    return gridsearchcv.best_estimator_.steps[-1][1].n_iter_ < gridsearchcv.best_estimator_.steps[-1][1].max_iter\n",
    "\n",
    "\n",
    "np.random.seed(31415) \n",
    "\n",
    "scaler = StandardScaler()\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "logistic = ...\n",
    "\n",
    "\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"imputer\", imp), (\"logistic\", logistic)])\n",
    "\n",
    "# you don't need to modify the max_iter param. If you do, keep it under 1000\n",
    "param_grid = {\n",
    "     # hint, prefix your param names with logistic__ to pass it to the logistic step\n",
    "     ...\n",
    "    ...\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# use f1_micro for scoring\n",
    "# use 7 folds\n",
    "gscv = ...\n",
    "\n",
    "\n",
    "gscv.fit(X_train, y_train)\n",
    "\n",
    "plot_results(gscv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480f0d67",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"Optimization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2547d234",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-59c0ba83bdd4f83f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Multi-class Metrics\n",
    "\n",
    "You may have noticed that the above problem is a multi-class problem. There are 8 different classes being predicted.\n",
    "\n",
    "To validate your solution from the above section, you will write your own multi-class precision function. You might have noticed that precision is defined using false positives and true positives -- both of which are binary. In order to use precision (recall and f1) in multi-class problems you need measure these using a one-vs-rest strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a3f580",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e96bbc6c101093f9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(gscv.best_estimator_, X_test, y_test)\n",
    "plt.xticks(rotation = -45);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e7d81f",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-624cfbf3f48d20cd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def multi_class_precision_macro(y_true, y_pred):\n",
    "    \"\"\"multi_class_precision_macro\n",
    "    This function computes precision for multiclass problems\n",
    "    \n",
    "    How does it work?\n",
    "    \n",
    "    First, figure out the unique labels in your prediction problem\n",
    "    Second, compute precision for each class in a one-vs-rest manner\n",
    "    Third, take the (unweighted) average of all these precision scores\n",
    "    \n",
    "    This is inappropriate for imbalanced class settings. In those cases you would want to use a weighted average.\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \n",
    "multi_class_precision_macro(y_test, gscv.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676522bb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"Multi-class Metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126a6774",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4f17d7c452ce6296",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Multi-class Classifiers\n",
    "\n",
    "In the first section, we used an inherently multiclass classifier, logistic regression. Logistic regression accomplishes this using a generalization of the sigmoid function called the softmax function (or the gibbs or boltzman distribution if you are from physics :) ). Several other classifier algorithms can be inherently multiclass such as naive bayes, neural networks, and decision trees. However some algorithms can not, namely those that use linear decision boundaries such as svm algorithms.\n",
    "\n",
    "For non-inherently mutli-class classifiers, you can still make multi-class predictions by a one-vs-rest strategy. This strategy involves training a classifier for every class.\n",
    "\n",
    "Here you will train an linear classifier using a one-vs-rest strategy.\n",
    "\n",
    "When we plot the decision boundaries, your plot should look something like this:\n",
    "\n",
    "![decision_boundaries](./index2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9cbe3d",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2ca428992d6d79ba",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train an SGD Classifier using a one vs rest strategy\n",
    "# \n",
    "# To do this, create a pipeline like in first question.\n",
    "# You will probably want to rescale your data AND impute missing values like in the above problem.\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets\n",
    "np.random.seed(0)\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :]  # we only take the first two features.\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)\n",
    "\n",
    "# In your pipeline add this step immediately before your SGDClassifier.\n",
    "# This compresses our data to 2D for visualization purposes\n",
    "# Don't worry if you aren't familiar with PCA...we're using purely for visualization purposes\n",
    "\n",
    "# Initialize a Standar scaler object:\n",
    "scaler = ...\n",
    "\n",
    "\n",
    "# Initialize a simple imputer that replace the missing values by np.nan\n",
    "# with the strategy of 'mean'\n",
    "imp = ...\n",
    "\n",
    "\n",
    "# initialize a PCA step for dimensionality reduction\n",
    "pca_step = ('pca', PCA(n_components=2))\n",
    "\n",
    "# Initialize a stochastic gradient descent Classifier with \n",
    "# the class_weight set as \"balanced\"\n",
    "classifier = ...\n",
    "\n",
    "\n",
    "# Put everything into a pipeline\n",
    "# Pipeline(steps=[...,pca_step,...])\n",
    "pipelines = ...\n",
    "\n",
    "# initialize the classifier over the pipelines\n",
    "onevrest_classifier = ...\n",
    "\n",
    "\n",
    "onevrest_classifier.fit(X_train, y_train)\n",
    "plot_confusion_matrix(onevrest_classifier, X_test, y_test)\n",
    "plt.xticks(rotation = -45);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b8b34f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"Multi-class Classifiers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860910a7",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b084fae50e5a0e24",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Visualize Your Multi-class Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f9c9d1",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9a81c6d80ffd91a0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_hyperplane(clf, min_x, max_x, linestyle):\n",
    "    # get the separating hyperplane\n",
    "    w = clf.coef_[0]\n",
    "    a = -w[0] / w[1]\n",
    "    xx = np.linspace(min_x - 5, max_x + 5)  # make sure the line is long enough\n",
    "    yy = a * xx - (clf.intercept_[0]) / w[1]\n",
    "    plt.plot(xx, yy, linestyle)\n",
    "    \n",
    "\n",
    "\n",
    "_X_reduced = pipe[:-1].fit(X_test, y_test).transform(X_test)\n",
    "\n",
    "plot_hyperplane(onevrest_classifier.estimators_[0][-1], _X_reduced[:,0].min(), _X_reduced[:,0].max(), 'b--')\n",
    "plot_hyperplane(onevrest_classifier.estimators_[1][-1], _X_reduced[:,0].min(), _X_reduced[:,0].max(), 'r--')\n",
    "plot_hyperplane(onevrest_classifier.estimators_[2][-1], _X_reduced[:,0].min(), _X_reduced[:,0].max(), 'g--')\n",
    "\n",
    "\n",
    "label_map = {\n",
    "    0: \"blue\",\n",
    "    1: \"red\",\n",
    "    2: \"green\"\n",
    "}\n",
    "\n",
    "plt.scatter(_X_reduced[:,0], _X_reduced[:,1],\n",
    "            s=100,\n",
    "            c=[label_map[y] for y in y_test],\n",
    "            linewidths=3,\n",
    "            edgecolors=[label_map[y] for y in onevrest_classifier.predict(X_test)])\n",
    "plt.ylim(_X_reduced[:,0].min(), _X_reduced[:,0].max());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccf6e4d",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ca18e295e26bd47f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# The End of D6\n",
    "Be sure to click `save` before you submit this Discussion Labs on Gradescope."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "Multi-class Classifiers": {
     "name": "Multi-class Classifiers",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(scaler, StandardScaler)\n>>> assert isinstance(imp, SimpleImputer)\n>>> assert isinstance(classifier, SGDClassifier)\n>>> assert isinstance(pipelines, Pipeline)\n>>> assert isinstance(onevrest_classifier, OneVsRestClassifier)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Multi-class Metrics": {
     "name": "Multi-class Metrics",
     "points": 0.5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert callable(multi_class_precision_macro)\n>>> # We correctly classified class \"a\" and misclassified class \"b\", \"c\".\n>>> # Therefore, the expected output is 1/3\n>>> output = multi_class_precision_macro(np.array([\"a\",\"b\",\"c\",\"a\"]), np.array([\"a\",\"c\",\"b\",\"a\"]))\n>>> assert np.isclose(output, 1/3, atol=1e-10)\n",
         "hidden": false,
         "locked": false,
         "points": 0.25
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Optimization": {
     "name": "Optimization",
     "points": 0.5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(logistic, LogisticRegression)\n>>> assert isinstance(param_grid, dict)\n>>> assert isinstance(gscv, GridSearchCV)\n",
         "hidden": false,
         "locked": false,
         "points": 0.25
        },
        {
         "code": ">>> # DO NOT EDIT THIS CELL - TESTING\n>>> assert check_for_convergence(gscv), \"oh no, your best model didn't converge\"\n",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
