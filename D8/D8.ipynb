{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc9d1b4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"D8.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d28b8a",
   "metadata": {},
   "source": [
    "# Discussion 8: Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5404811c",
   "metadata": {},
   "source": [
    "\n",
    "Neural networks are a type of machine learning model that is loosely inspired by the structure of the human brain. They consist of interconnected nodes, or \"neurons,\" organized into layers. Each neuron receives input from the neurons in the previous layer, processes that input, and then sends output to the neurons in the next layer.\n",
    "\n",
    "In a supervised machine learning context, the goal of a neural network is to learn a function that maps inputs to outputs based on a set of labeled training examples. During training, the network adjusts the weights on the connections between neurons in order to minimize the difference between its predicted outputs and the true outputs for the training examples.\n",
    "\n",
    "There are many different types of neural networks, each with its own architecture and training algorithm. Some common types include feedforward neural networks, convolutional neural networks (CNNs), and recurrent neural networks (RNNs). Each type is suited to different types of problems and data.\n",
    "\n",
    "Neural networks are a powerful tool for machine learning, and have been used successfully in many applications, including image and speech recognition, natural language processing, and more. However, they can also be computationally intensive and require careful tuning to achieve good performance.\n",
    "\n",
    "\n",
    "## Instructions: \n",
    "\n",
    "In this lab, you will practice implementing a simple neural network from scratch using **Pytorch**. \n",
    "\n",
    "\n",
    "Please note that there are **no hidden tests** for this discussion lab. In other words, if you pass the public test cases, you will gain full points for the questions. \n",
    "\n",
    "Read the markdown cells carefully, as they'll provide hints towards writing your solutions. For each question, you'll be expected to import the required packages and implement based upon the description. All necessary information will be provided, so again, read carefully!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90387b31",
   "metadata": {},
   "source": [
    "## Task Description: Classifying digits (0-9) using a feedforward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6398dca0",
   "metadata": {},
   "source": [
    "In this lab, we will focus on creating a simple **feed-forward classification neural network** to classify handwritten digits between 0-9 from the MNIST dataset into their respective classes. \n",
    "\n",
    "\n",
    "A feed-forward neural network is a classification algorithm that consists of a large number of perceptrons, organized in layers & each unit in the layer is connected with all the units or neurons present in the previous layer. These connections are not all equal and can differ in strengths or weights. The weights on these connections cipher the knowledge of the network.\n",
    "\n",
    "When the data enters at the inputs and passes through the network, layer by layer, there is no feedback in between the layers until it arrives at the outputs. This is the reason why they are known as a feedforward neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4b0d4f",
   "metadata": {},
   "source": [
    "Before, we get started we need to install **Pytorch**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9db26d2",
   "metadata": {},
   "source": [
    "About Pytorch - https://pytorch.org/\n",
    "\n",
    "Pytorch is an open-source machine learning and deep learning framework widely used in applications such as natural language processing, image classification and computer vision applications. It was developed by Facebook’s AI Research and later adapted by several conglomerates such as  Uber, Twitter, Salesforce, and NVIDIA. \n",
    "\n",
    "PyTorch comes with several specially developed modules like torchtext,  torchvision and other classes such as torch.nn, torch.optim, Dataset, and Dataloader to help you create and train neural networks to work with a different machine and deep learning areas. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f0d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch==1.12.0\n",
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7c5cde",
   "metadata": {},
   "source": [
    "**Note: Please restart your kernel after pip installing the above packages. Click kernel > Restart.** \n",
    "\n",
    "\n",
    "Then run the following import cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdda0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70edd0bd",
   "metadata": {},
   "source": [
    "Cool! Now that we imported torch and torchvision, let's focus on loading our dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf96e94",
   "metadata": {},
   "source": [
    "### About the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c385c756",
   "metadata": {},
   "source": [
    "\n",
    "Torchvision provides many built-in datasets in the torchvision.datasets module, as well as utility classes for building your own datasets. - https://pytorch.org/vision/stable/datasets.html\n",
    "\n",
    "\n",
    "We'll be using one of these built-in datasets for our classification task. \n",
    "\n",
    "\n",
    "\n",
    "The **MNIST** dataset, also known as the Modified National Institute of Standards and Technology dataset, consists of 60,000 small square 28×28 grayscale images of handwritten digits between 0 to 9 divided into ten different classes. This dataset is mainly used for text classification using deep learning models.\n",
    "\n",
    "The MNIST database contains **60,000 training images** and **10,000 testing images**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3326c398",
   "metadata": {},
   "source": [
    "### Load the MNIST dataset from Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3013d0bb",
   "metadata": {},
   "source": [
    "The following cell transforms the dataset into a Pytorch friendly format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ce3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "# Read in train_data and test_data from built-in MNIST dataset, \n",
    "# transform into Pytorch tensor format\n",
    "\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ea0adc",
   "metadata": {},
   "source": [
    "**Question 1:** Store the size of the our training dataset and testing dataset in the following variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b84ded5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_size = ...\n",
    "test_size = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345beaf9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"Q1.1 dataset_size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab13dcb4",
   "metadata": {},
   "source": [
    "Since the entire dataset is around 70k images - which will take a TON of time to train on a CPU, we will take the first 10% of images for our train and test set. Don't worry if you don't fully understand the details - just run the code provided! If you are courious about the purpose and the function of each line, feel free to post a Piazza post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e2ff47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the entire dataset is around 60k images \n",
    "# - which will take a TON of time to train on a CPU\n",
    "# We subset the entire set - and pick the first 10% for train and test. \n",
    "train_dataset = Subset(train_data, indices=range(len(train_data) // 10))\n",
    "test_dataset = Subset(train_data, indices=range(len(test_data) // 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcc813b",
   "metadata": {},
   "source": [
    "PyTorch's dataloader takes a dataset object as input, which is responsible for loading and returning individual data samples. The dataloader then takes care of batching, shuffling, and multiprocessing the data samples, making it easy to feed them into a deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bd1e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just run this cell to use Pytorch dataloader to load train and test sets \n",
    "# Note that we specify batch size = 100. \n",
    "# This means that we will have 60 batches in total \n",
    "# - and each batch contains 100 images for the train set \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=100, \n",
    "                                           shuffle=True)\n",
    "\n",
    "# Note that we specify batch size = 100. \n",
    "# This means that we will have 10 batches in total \n",
    "# - and each batch contains 100 images for the test set \n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcca94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick check to ensure our train_loader loaded our 6000 train images properly \n",
    "print('For the train set:')\n",
    "print('Total number of batches:', len(train_loader))\n",
    "print('Number of images in each batch in train set:', train_loader.batch_size)\n",
    "print('Total number of images in train set:', len(train_loader.dataset))\n",
    "print()\n",
    "\n",
    "\n",
    "# A quick check to ensure our test_loader loaded our 1000 test images properly \n",
    "print('For the test set:')\n",
    "print('Total number of batches:', len(test_loader))\n",
    "print('Number of images in each batch in test set:', test_loader.batch_size)\n",
    "print('Total number of images in test set:', len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c85bef",
   "metadata": {},
   "source": [
    "Great! Now that we have successfully loaded our train and test sets, let's take a quick look at what our test set images look like. \n",
    "\n",
    "\n",
    "Please run the following code cell to take a look at the 10 random images in our test set. \n",
    "\n",
    "The ground truth labels are displayed in blue as the title of the plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969d508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = iter(test_loader)\n",
    "example_data, example_targets = next(examples)\n",
    "\n",
    "\n",
    "params = {\"text.color\" : \"blue\",\n",
    "          \"xtick.color\" : \"black\",\n",
    "          \"ytick.color\" : \"black\"}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "indices = np.random.randint(0, len(test_loader), size=10)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 5, figsize=(10, 5))\n",
    "axs = axs.flatten()\n",
    "examples = iter(test_loader)\n",
    "\n",
    "for i, index in enumerate(indices):\n",
    "    # Get the image and ground truth label\n",
    "\n",
    "    example_data, example_targets = next(examples)\n",
    "    image, label = example_data[index][0], example_targets[index].item()\n",
    "\n",
    "    # Plot the image with its ground truth\n",
    "    axs[i].imshow(image.reshape(28, 28), cmap='gray')\n",
    "    axs[i].set_title(f'GT: {label}')\n",
    "    axs[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea1f048",
   "metadata": {},
   "source": [
    "Now, let's focus on building our fully connected neural network that will classify these test images into one of 10 different classes, i.e the digits (0-9). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d303cc",
   "metadata": {},
   "source": [
    "## Creating our Fully Connected Network with one hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a0bee3",
   "metadata": {},
   "source": [
    "We will first define our hyperparameters for our neural network. \n",
    "\n",
    "**Question 2:** Given the hand written digit as the input to our model, what should be the input size of our Fully Connected Network?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20032968",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "examples = iter(test_loader)\n",
    "example_data, example_targets = next(examples)\n",
    "image, label = example_data[index][0], example_targets[index].item()\n",
    "\n",
    "# Take a look at our input: image\n",
    "print(image)\n",
    "\n",
    "# Based on that input, what should be our network's input size?\n",
    "input_size = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81070987",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"Q1.2 Input Size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc508791",
   "metadata": {},
   "source": [
    "- We then set our hidden layer size to 500 units.\n",
    "\n",
    "- num_classes is set to 10 since this is a multiclass classification problem with 10 classes. \n",
    "\n",
    "- As mentioned before, our batch_size is set to 100. \n",
    "\n",
    "- Set learning rate of network to 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef86b9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our hidden layer will have input size 500. \n",
    "hidden_size = 500 \n",
    "\n",
    "# num_classes = 10, since we want to classify digits into one of 10 classes \n",
    "num_classes = 10\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40bdd70",
   "metadata": {},
   "source": [
    "## Question 1:  Linear Layers \n",
    "\n",
    "The code cell below defines a fully connected neural network with a single hidden layer. Your job is to fill in the lines for the first and second linear layer. \n",
    "\n",
    "You can accomplish this using the **nn.Linear** function and setting the appropriate input and output sizes for each layer - https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\n",
    "\n",
    "**Hint**: Use the hyperparameters we defined above! \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2263bf8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "\n",
    "# The neural network is defined as a class called NeuralNet, which inherits from the nn.Module class in PyTorch. \n",
    "# This allows the network to take advantage of the built-in functionality of PyTorch for training and optimization.\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    \n",
    "    # initializes the neural network and sets its parameters. \n",
    "    # It takes three arguments - input_size, hidden_size, and num_classes \n",
    "    # input_size - the size of the input layer, \n",
    "    # hidden_size - the number of neurons in the hidden layer, \n",
    "    # num_classes - the number of output classes\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "\n",
    "        # Your task: Create the first linear layer using nn.Linear \n",
    "        # Hint: Think about the input size of the first layer. \n",
    "        # Since the hidden layer is next, what should the output size of this first linear layer be?\n",
    "        self.l1 = ...\n",
    "        \n",
    "        \n",
    "        # a Rectified Linear Unit (ReLU) activation function applied to first layer \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Your task: Create the second linear layer using nn.Linear \n",
    "        # Hint: Think about the input size of the second layer (This layer is connected to the hidden layer!)\n",
    "        # This layer produces the final output of the network so what should the output size be?\n",
    "        self.l2 = ...\n",
    " \n",
    "\n",
    "    # defines how the input data is processed through the neural network. \n",
    "    # connect each layer together as following:  l1 -> relu -> l2\n",
    "    def forward(self, x):\n",
    "        ...\n",
    "        return out\n",
    "    \n",
    "\n",
    "# Create an instance of NeuralNet and store it in model\n",
    "model = NeuralNet(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86000209",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"Q1.3 Linear Layers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4cfe99",
   "metadata": {},
   "source": [
    "Great! Now that we've created an instance of NeuralNet called model, let's take a look at our model architecture. \n",
    "\n",
    "Run the following code cell provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d8a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a73a1e0",
   "metadata": {},
   "source": [
    "What do you observe? Does your network have two linear layers? Make sure your network architecture is defined correctly before moving on to the next part. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e31263f",
   "metadata": {},
   "source": [
    "## Testing the network - before Training \n",
    "\n",
    "\n",
    "Let's compare the accuracy of our network on the test images **before** and **after** training. \n",
    "\n",
    "We expect the network to have really poor accuracy (since all the weights are randomly initialized, and no learning or weight updates have occurred). \n",
    "\n",
    "\n",
    "Run the following code cell to see the accuracy of our un-trained network on 1000 test images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6bb7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 1000 test images: {acc} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985ccd2e",
   "metadata": {},
   "source": [
    "As expected, our network has really poor accuracy! Let's take a quick look at our predictions on the images. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88526127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot random 10 images from MNIST test set with ground truth and predicted label \n",
    "\n",
    "import numpy as np\n",
    "indices = np.random.randint(0, len(test_loader), size=10)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 5, figsize=(10, 5))\n",
    "axs = axs.flatten()\n",
    "examples = iter(test_loader)\n",
    "\n",
    "for i, index in enumerate(indices):\n",
    "    # Get the image and ground truth label\n",
    "\n",
    "    example_data, example_targets = next(examples)\n",
    "    image, label = example_data[index][0], example_targets[index].item()\n",
    "\n",
    "    # Make a prediction with the model\n",
    "    with torch.no_grad():\n",
    "        image = image.reshape(-1, 28*28)\n",
    "        prediction = model(image)\n",
    "        predicted_label = torch.argmax(prediction, dim=1).item()\n",
    "\n",
    "    # Plot the image with its ground truth and predicted labels\n",
    "    axs[i].imshow(image.reshape(28, 28), cmap='gray')\n",
    "    axs[i].set_title(f'GT: {label}, Pred: {predicted_label}')\n",
    "    axs[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01b7424",
   "metadata": {},
   "source": [
    "You'll notice that the network does a REALLY bad job at classifying the digits - often predicting the same digit for many images. These are **RANDOM and incorrect**. \n",
    "\n",
    "Since the weights of the network are initialized randomly when the network is created, the output of the network will also be random. \n",
    "Without training the network, the weights remain unchanged, and the network has no ability to recognize patterns in the input data. \n",
    "Therefore, the network has not learned any meaningful patterns in the data, and will likely make random predictions for each input image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c230fd9d",
   "metadata": {},
   "source": [
    "## Question 2: Training the network\n",
    "\n",
    "\n",
    "In the following code cells, we will set up the training loop for the network. \n",
    "\n",
    "Your task will be to fill in the loss function within the loop which is used to calculate the error between the predicted output and the actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a24f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify loss function\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "# Specify optimization algorithm to be used \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac67d38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_total_batches = len(train_loader)\n",
    "print('Total Batches in train set:', n_total_batches)\n",
    "losses = []\n",
    "\n",
    "# Outer loop - runs over number of epochs \n",
    "for epoch in range(num_epochs):\n",
    "    # Loop over each image and label \n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        \n",
    "        # origin shape: [100, 1, 28, 28]\n",
    "        # resized: [100, 784] to be able to pass into network\n",
    "        images = images.reshape(-1, 28*28)\n",
    "\n",
    "        # Your task: Fill in the forward pass\n",
    "        # Forward pass - pass input image through network \n",
    "        outputs = ...\n",
    "        \n",
    "        # Your task: Fill in the loss function \n",
    "        # that calculates the error between the predicted output and the actual labels\n",
    "        # Hint: We already defined this above. Think about what arguments a loss function should take. \n",
    "        loss = ...\n",
    " \n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{n_total_batches}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5045e39",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"Q2.1 Training Loop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6d0d30",
   "metadata": {},
   "source": [
    "Great! We have successfully trained our network. Since we're only training this network for 2 epochs, you may see a fluctuation in the loss values per batch. As a whole however, the loss will generally decrease, as you train the network for a higher number of epochs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a05a927",
   "metadata": {},
   "source": [
    "## Testing the network - After Training \n",
    "\n",
    "\n",
    "Let's compare the accuracy of our network on the test images now **after** training. \n",
    "\n",
    "We expect the network to have improved accuracy (since all the weights have been updated during the training process and we expect the network to have learned to recognize visual features to distinguish between input images.)\n",
    "\n",
    "\n",
    "Run the following code cell to see the accuracy of our **trained network** on 1000 test images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f74328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 1000 test images: {acc} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b21e089",
   "metadata": {},
   "source": [
    "Whew, that's a huge jump in accuracy! Seems like the weights in our network have been adjusted to minimize error between predicted and output labels, and our network has learned to accurately recognize and classify digits in the test images. \n",
    "\n",
    "\n",
    "Let's compare the ground truth and predictions for 10 random images in our test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0008488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot random 10 images from MNIST test set with ground truth and predicted label \n",
    "\n",
    "import numpy as np\n",
    "indices = np.random.randint(0, len(test_loader), size=10)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 5, figsize=(10, 5))\n",
    "axs = axs.flatten()\n",
    "examples = iter(test_loader)\n",
    "\n",
    "for i, index in enumerate(indices):\n",
    "    # Get the image and ground truth label\n",
    "\n",
    "    example_data, example_targets = next(examples)\n",
    "    image, label = example_data[index][0], example_targets[index].item()\n",
    "\n",
    "    # Make a prediction with the model\n",
    "    with torch.no_grad():\n",
    "        image = image.reshape(-1, 28*28)\n",
    "\n",
    "        prediction = model(image)\n",
    "        predicted_label = torch.argmax(prediction, dim=1).item()\n",
    "\n",
    "    # Plot the image with its ground truth and predicted labels\n",
    "    axs[i].imshow(image.reshape(28, 28), cmap='gray')\n",
    "    axs[i].set_title(f'GT: {label}, Pred: {predicted_label}')\n",
    "    axs[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b097df",
   "metadata": {},
   "source": [
    "We can see that the predictions now match our ground truth for most images. \n",
    "\n",
    "\n",
    "It's important to note that the performance of the network can depend on several factors, such as the network architecture, hyperparameters, and the size and complexity of the dataset. Additionally as with other supervised ML algorithms, the network may not be able to generalize well to new, unseen data if it was overfitted on the training data.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028d19fd",
   "metadata": {},
   "source": [
    "Congratulations! You have successfully trained your first neural network and used it to classify 10000 images from MNIST. \n",
    "\n",
    "# Submission Guidelines\n",
    "## DO NOT USE `shutil`. Please Directly Submit this `D8.ipynb`\n",
    "\n",
    "Have a look back over your answers, and also make sure to `Restart & Run All` from the kernel menu to double check that everything is working properly. This restarts everything and runs your code from top to bottom.\n",
    "\n",
    "When you are ready to submit your assignment, you can click `Validate` at the top. Note that in some assignments the code will take too long to run and validation may fail. Validation is just a final check that all the asserts are passing without failing.\n",
    "\n",
    "Once you're happy with your work, click the disk icon to save, and submit the zip file onto gradescope. **You MUST submit all the required component to receive credit.**\n",
    "\n",
    "Note that you can submit at any time, but **we grade your most recent submission**. This means that **if you submit an updated notebook after the submission deadline, it will be marked as late**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "Q1.1 dataset_size": {
     "name": "Q1.1 dataset_size",
     "points": 0.2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert train_size == 60000\n>>> assert test_size == 10000\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Q1.2 Input Size": {
     "name": "Q1.2 Input Size",
     "points": 0.2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert input_size == 784, \"Have you flattern the image size and calculate the total number of pixel in the image?\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Q1.3 Linear Layers": {
     "name": "Q1.3 Linear Layers",
     "points": 1.2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # Layer one tests\n>>> assert isinstance(model.l1, nn.Linear), \"Is your layer one a linear layer?\"\n>>> assert model.l1.in_features == 784, \"Have you correctly specify the input feature of the first layer?\"\n>>> assert model.l1.out_features == 500, \"Have you correctly specify the out feature of the first layer?\"\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # Layer two tests\n>>> assert isinstance(model.l2, nn.Linear), \"Is your layer one a linear layer?\"\n>>> assert model.l2.in_features == 500, \"Have you correctly specify the input feature of the first layer?\"\n>>> assert model.l2.out_features == 10, \"Have you correctly specify the out feature of the first layer?\"\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> forward_sequence = str(model.forward).split(\"\\n\")\n>>> assert forward_sequence[1] == \"  (l1): Linear(in_features=784, out_features=500, bias=True)\", \"Have you correctly connect the input to the first layer?\"\n>>> assert forward_sequence[2] == \"  (relu): ReLU()\", \"Have you connect the first layer to the ReLU?\"\n>>> assert forward_sequence[3] == \"  (l2): Linear(in_features=500, out_features=10, bias=True)\", \"Have you connect the ReLU to the output Layer?\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "Q2.1 Training Loop": {
     "name": "Q2.1 Training Loop",
     "points": 0.4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert losses[-1] < 0.3, \"Did your loss converge?\"\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> # Test the model\n>>> # In test phase, we don't need to compute gradients (for memory efficiency)\n>>> with torch.no_grad():\n...     n_correct = 0\n...     n_samples = 0\n...     for images, labels in test_loader:\n...         images = images.reshape(-1, 28*28)\n...         outputs = model(images)\n...         # max returns (value ,index)\n...         _, predicted = torch.max(outputs.data, 1)\n...         n_samples += labels.size(0)\n...         n_correct += (predicted == labels).sum().item()\n...     acc = 100.0 * n_correct / n_samples\n>>> assert acc > 0.90, \"Is your classifier achiving at least 90% accuracy?\"\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
